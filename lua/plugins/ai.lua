-- AI-powered coding assistance and chat interfaces
-- Contains configurations for AI tools that provide code suggestions, explanations, and interactive chat
return {
  -- CodeCompanion: Interactive AI chat interface with support for multiple LLM providers (Ollama, Claude)
  -- Provides code explanation, fixing, testing, and commit message generation
  -- {
  --   "olimorris/codecompanion.nvim",
  --   dependencies = {
  --     "nvim-lua/plenary.nvim",
  --     "nvim-treesitter/nvim-treesitter",
  --   },
  --   keys = {
  --     { "<leader>a", group = "ai", desc = "ai" },
  --     { "<leader>aa", "<cmd>CodeCompanionActions<cr>", { noremap = true, silent = true }, desc = " Action Panel" },
  --     { "<leader>ac", "<cmd>CodeCompanionChat Toggle<cr>", { noremap = true, silent = true }, desc = " Open Chat" },
  --     { "<leader>ae", "<cmd>CodeCompanion /explain<cr>", { noremap = true, silent = true }, desc = " Explain Code" },
  --     { "<leader>af", "<cmd>CodeCompanion /fix<cr>", { noremap = true, silent = true }, desc = " Fix Code" },
  --     { "<leader>at", "<cmd>CodeCompanion /test<cr>", { noremap = true, silent = true }, desc = " Test Code" },
  --     {
  --       "<leader>ag",
  --       "<cmd>CodeCompanion /commit<cr>",
  --       { noremap = true, silent = true },
  --       desc = " Github Commit Message",
  --     },
  --     { "<leader>ao", "<cmd>CodeCompanionChat Add<cr>", { noremap = true, silent = true }, desc = " Add to Chat" },
  --   },
  --   config = function()
  --     require("codecompanion").setup({
  --       strategies = {
  --         chat = {
  --           adapter = "ollama",
  --         },
  --         inline = {
  --           adapter = "ollama",
  --         },
  --       },
  --       display = {
  --         chat = {
  --           intro_message = "CodeCompanion ✨! Press ? for options",
  --           show_header_separator = false,
  --           separator = "─", -- The separator between the different messages in the chat buffer
  --           show_references = true, -- Show references (from slash commands and variables) in the chat buffer?
  --           show_settings = false, -- Show LLM settings at the top of the chat buffer?
  --           show_token_count = false, -- Show the token count for each response?
  --           start_in_insert_mode = false, -- Open the chat buffer in insert mode?
  --         },
  --       },
  --     })
  --   end,
  -- },

  -- Avante: Advanced AI coding assistant with inline suggestions and chat functionality
  -- Supports multiple providers (Ollama, Claude) with image pasting and markdown rendering
  -- {
  --   "yetone/avante.nvim",
  --   -- if you want to build from source then do `make BUILD_FROM_SOURCE=true`
  --   -- ⚠️ must add this setting! ! !
  --   build = function()
  --     -- conditionally use the correct build system for the current OS
  --     if vim.fn.has("win32") == 1 then
  --       return "powershell -ExecutionPolicy Bypass -File Build.ps1 -BuildFromSource false"
  --     else
  --       return "make"
  --     end
  --   end,
  --   event = "VeryLazy",
  --   version = false, -- Never set this value to "*"! Never!
  --   keys = {
  --     { "<leader>aC", ":AvanteClear<CR>", desc = "avante: clear current chat" },
  --   },
  --   ---@module 'avante'
  --   ---@type avante.Config
  --   opts = {
  --     -- add any opts here
  --     -- for example
  --     provider = "ollama",
  --     providers = {
  --       ollama = {
  --         endpoint = "http://127.0.0.1:11434",
  --         model = "deepseek-coder:1.3b",
  --         timeout = 30000, -- Timeout in milliseconds
  --       },
  --     },
  --     -- provider = "claude",
  --     -- providers = {
  --     --   claude = {
  --     --     endpoint = "https://api.anthropic.com",
  --     --     model = "claude-sonnet-4-20250514",
  --     --     timeout = 30000, -- Timeout in milliseconds
  --     --     extra_request_body = {
  --     --       temperature = 0.75,
  --     --       max_tokens = 20480,
  --     --     },
  --     --   },
  --     -- },
  --   },
  --   dependencies = {
  --     "nvim-lua/plenary.nvim",
  --     "MunifTanjim/nui.nvim",
  --     --- The below dependencies are optional,
  --     "nvim-mini/mini.pick", -- for file_selector provider mini.pick
  --     "nvim-telescope/telescope.nvim", -- for file_selector provider telescope
  --     "hrsh7th/nvim-cmp", -- autocompletion for avante commands and mentions
  --     "ibhagwan/fzf-lua", -- for file_selector provider fzf
  --     "stevearc/dressing.nvim", -- for input provider dressing
  --     "folke/snacks.nvim", -- for input provider snacks
  --     "nvim-tree/nvim-web-devicons", -- or nvim-mini/mini.icons
  --     -- "zbirenbaum/copilot.lua", -- for providers='copilot'
  --     {
  --       -- support for image pasting
  --       "HakonHarnes/img-clip.nvim",
  --       event = "VeryLazy",
  --       opts = {
  --         -- recommended settings
  --         default = {
  --           embed_image_as_base64 = false,
  --           prompt_for_file_name = false,
  --           drag_and_drop = {
  --             insert_mode = true,
  --           },
  --           -- required for Windows users
  --           use_absolute_path = true,
  --         },
  --       },
  --     },
  --     {
  --       -- Make sure to set this up properly if you have lazy=true
  --       "MeanderingProgrammer/render-markdown.nvim",
  --       opts = {
  --         file_types = { "markdown", "Avante" },
  --       },
  --       ft = { "markdown", "Avante" },
  --     },
  --   },
  -- },
}
